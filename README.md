# AI-project
Groupe 49
# ğŸ§  Azure RAG PDF Indexer & Assistant

Ce projet est un **PoC RAG (Retrieval-Augmented Generation)** qui permet Ã  GPT-4 d'interagir avec un ou plusieurs documents PDF hÃ©bergÃ©s localement, vectorisÃ©s et stockÃ©s dans **Azure AI Search**. L'utilisateur pose une question via une interface web (Streamlit), et GPT gÃ©nÃ¨re une rÃ©ponse basÃ©e uniquement sur le contenu documentaire indexÃ©.

---

[README in English](https://github.com/RedZNouggy/AI-project/blob/main/README-EN.MD)

## ğŸ“¦ FonctionnalitÃ©s

- ğŸ” Extraction automatique de texte depuis un ou plusieurs fichiers PDF
- âœ‚ï¸ DÃ©coupage intelligent des documents en blocs sÃ©mantiques
- ğŸ”¢ GÃ©nÃ©ration d'embeddings via `text-embedding-ada-002` (Azure OpenAI)
- ğŸ“¥ Indexation des chunks vectorisÃ©s dans Azure AI Search
- ğŸ’¬ Appel Ã  GPT-4 avec contexte documentaire injectÃ©
- ğŸŒ Interface utilisateur simple via Streamlit

---

## ğŸ“ Structure du projet

```
.
â”œâ”€â”€ config.py              # ParamÃ¨tres Azure (clÃ©s, endpoints, noms de dÃ©ploiements)
â”œâ”€â”€ utils.py               # Fonctions utilitaires : extraction PDF, embeddings, chunking
â”œâ”€â”€ index_data.py          # Script d'injection des documents PDF dans Azure Search
â”œâ”€â”€ main.py                # Application frontend Streamlit (Q&A)
â”œâ”€â”€ data/docs/             # Dossier contenant les PDF Ã  indexer
â””â”€â”€ requirements.txt       # DÃ©pendances Python
```

---

## âš™ï¸ Installation

### 1. Cloner le projet

```bash
git clone https://github.com/RedZNouggy/AI-project.git
cd AI-project
```

### 2. CrÃ©er un environnement virtuel (optionnel mais recommandÃ©)

```bash
python -m venv .venv
source .venv/bin/activate  # Linux/macOS
.venv\Scripts\activate     # Windows
```

### 3. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

---

## ğŸ” Configuration

Remplir le fichier `config.py` avec les valeurs suivantes :

```python
AZURE_OPENAI_API_KEY = "<MY_API_KEY>"
AZURE_OPENAI_ENDPOINT = "https://<MY_URL>.openai.azure.com/"
AZURE_OPENAI_API_VERSION = "2023-05-15"

EMBEDDING_DEPLOYMENT_NAME = "text-embedding-ada-002"
GPT_DEPLOYMENT_NAME = "<GPT_DEPLOYMENT_NAME>"

AZURE_SEARCH_ENDPOINT = "https://<SEARCH_URL>.search.windows.net"
AZURE_SEARCH_KEY = "<SEARCH_API_KEY>"
AZURE_SEARCH_INDEX_NAME = "rag-index"
```

---

## ğŸ“„ Injection des documents PDF

DÃ©pose tes fichiers PDF dans le dossier `data/docs/` :

```
data/docs/
â”œâ”€â”€ contrat_client.pdf
â”œâ”€â”€ norme_iso27001.pdf
â””â”€â”€ politique_sÃ©curitÃ©.pdf
```

Puis lance :

```bash
python index_data.py
```

âœ”ï¸ Ce script :
- CrÃ©e (ou met Ã  jour) lâ€™index `rag-index`
- Injecte tous les documents PDF du dossier `data/docs/`
- Ajoute un champ `source` pour identifier dâ€™oÃ¹ viennent les chunks

---

## ğŸ’¬ Lancer lâ€™interface utilisateur

```bash
streamlit run main.py
```

Lâ€™interface web sâ€™ouvre automatiquement Ã  [http://localhost:8501](http://localhost:8501)

---

## ğŸ§  Exemple dâ€™utilisation

> ğŸ’¬ **Question** : Combien de temps faut-il faire cuire un fondant au chocolat ?
> ğŸ¤– **RÃ©ponse** : Selon la recette (source : livre_recettes_chocolat.pdf), le fondant au chocolat doit cuire 10 Ã  12 minutes Ã  180Â°C pour obtenir un cÅ“ur coulant.
> ğŸ’¬ **Question :** Quels sont les dÃ©lais de rÃ©solution en cas de panne critique ?  
> ğŸ¤– **RÃ©ponse :** Selon le contrat (source : contrat_client.pdf), les pannes critiques doivent Ãªtre traitÃ©es sous 4h ouvrÃ©es.

---

## ğŸ›¡ï¸ SÃ©curitÃ©

- Aucun contenu nâ€™est envoyÃ© Ã  des tiers hors Azure.
- Les documents PDF restent locaux, seuls les vecteurs sont stockÃ©s dans Azure Search.
- GPT n'a accÃ¨s quâ€™au contexte injectÃ©.

---

## ğŸ“Œ PrÃ©requis Azure

- Azure OpenAI avec :
  - DÃ©ploiement `gpt-4`
  - DÃ©ploiement `text-embedding-ada-002`
- Azure AI Search (`Basic` ou supÃ©rieur)

---

## ğŸ“ƒ Licence

Projet dÃ©monstratif
